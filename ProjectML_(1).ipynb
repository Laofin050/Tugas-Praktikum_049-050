{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ProjectML_(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laofin050/Tugas-Praktikum_049-050/blob/main/ProjectML_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0SzgFqyKIEO"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znZNiPStKG2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ba884a-1009-4b0d-b7e4-8cc47ecdec34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4PYIqmiKW0U"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/ProjectPrakML\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZiO_VX5K2hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830ce3aa-c28b-4229-a4d8-1618951e04dd"
      },
      "source": [
        "%cd /content/drive/My Drive/ProjectPrakML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ProjectPrakML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMPb0sEcLChG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca34c5e8-4b2c-4e76-acc6-b37fa4587de2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest_xray  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgUd7KhlLCce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8384415-2cbe-4461-e8cd-4bc0dcafd3d0"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content/drive/My Drive/ProjectPrakML\n",
            "100% 2.29G/2.29G [00:45<00:00, 50.9MB/s]\n",
            "100% 2.29G/2.29G [00:45<00:00, 53.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-1Dh2OLB-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c6bfc6-63a0-4d4b-fee1-ea18e8d7371e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest-xray-pneumonia.zip  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKHXfWRXLCNM"
      },
      "source": [
        "!unzip \\*.zip &> /dev/null && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnPw9ZFKt9Cy",
        "outputId": "de6d0d20-6586-4721-cedf-1b879a8cf5b6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest_xray  kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwxQJds1t2sZ"
      },
      "source": [
        "from os import mkdir\n",
        "\n",
        "mkdir ('New')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMsY7rkm6odR",
        "outputId": "d07b22c8-6d35-4477-e562-9b9ba38105c3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest_xray  kaggle.json  New\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoIUN0SXt9z1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "280f4540-a8f0-477b-a96f-f3e0cbf642ee"
      },
      "source": [
        "import shutil,sys\n",
        "\n",
        "shutil.move(\"/content/drive/My Drive/ProjectPrakML/chest_xray/chest_xray/test/NORMAL\", \"/content/drive/My Drive/ProjectPrakML/New\")\n",
        "shutil.move(\"/content/drive/My Drive/ProjectPrakML/chest_xray/chest_xray/test/PNEUMONIA\", \"/content/drive/My Drive/ProjectPrakML/New\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/ProjectPrakML/New/PNEUMONIA'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ_kUTbbXqXy"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx0D7wcFsEm2"
      },
      "source": [
        "%rm -rf test\n",
        "%rm -rf train\n",
        "%rm -rf valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZTQwSHXXpXb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "TRAIN_DIR = \"/content/drive/My Drive/ProjectPrakML/train/\"\n",
        "VALID_DIR =\"/content/drive/My Drive/ProjectPrakML/valid/\"\n",
        "TEST_DIR =\"/content/drive/My Drive/ProjectPrakML/test/\"\n",
        "\n",
        "os.mkdir(TRAIN_DIR)\n",
        "os.mkdir(VALID_DIR)\n",
        "os.mkdir(TEST_DIR)\n",
        "\n",
        "for label in ['NORMAL', 'PNEUMONIA']:\n",
        "    os.mkdir(TRAIN_DIR+label)\n",
        "    os.mkdir(VALID_DIR+label)\n",
        "    os.mkdir(TEST_DIR+label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zil9EPBz9ouI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb325db-432c-44db-a6e8-e3c847e2405d"
      },
      "source": [
        "import random\n",
        "\n",
        "def train_valid_test_split(source, train_dir, valid_dir, test_dir,train_size, valid_size, test_size):\n",
        "    # get files\n",
        "    files = []\n",
        "    for filename in os.listdir(source):\n",
        "        file = source + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "    \n",
        "    # train valid split\n",
        "    train_size = int(len(files) * (1-(valid_size + train_size)))\n",
        "    valid_size = int(len(files) * (1-(valid_size + test_size)))\n",
        "    test_size = int(len(files) * (1-train_size))\n",
        "  \n",
        "    # shuffle the dataset\n",
        "    shuffled_files = random.sample(files, len(files))\n",
        "    \n",
        "    train_set = shuffled_files[train_size:valid_size]\n",
        "    valid_set = shuffled_files[valid_size:]\n",
        "    test_set = shuffled_files[:train_size]\n",
        "    \n",
        "    for filename in train_set:\n",
        "        filepath = source + filename\n",
        "        destination = train_dir + filename\n",
        "        copyfile(filepath, destination)\n",
        "        \n",
        "    for filename in valid_set:\n",
        "        filepath = source + filename\n",
        "        destination = valid_dir + filename\n",
        "        copyfile(filepath, destination)\n",
        "    \n",
        "    for filename in test_set:\n",
        "        filepath = source + filename\n",
        "        destination = test_dir + filename\n",
        "        copyfile(filepath, destination)\n",
        "\n",
        "SOURCE = \"/content/drive/My Drive/ProjectPrakML/New/\"\n",
        "\n",
        "for label in ['NORMAL', 'PNEUMONIA']:\n",
        "    print(label)\n",
        "    train_valid_test_split(SOURCE+label+'/',  TRAIN_DIR +label+'/', VALID_DIR +label+'/', TEST_DIR +label+'/', train_size=0.8, valid_size=0.19, test_size=0.01)\n",
        "    print('Total images: ', len(os.listdir(SOURCE +label+'/')))\n",
        "    print('Training: ', len(os.listdir(TRAIN_DIR +label+'/')))\n",
        "    print('Validation: ', len(os.listdir(VALID_DIR +label+'/')))\n",
        "    print('Testing: ', len(os.listdir(TEST_DIR +label+'/')))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NORMAL\n",
            "Total images:  234\n",
            "Training:  185\n",
            "Validation:  47\n",
            "Testing:  2\n",
            "\n",
            "PNEUMONIA\n",
            "Total images:  390\n",
            "Training:  309\n",
            "Validation:  78\n",
            "Testing:  3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJ-FkSNGTaY"
      },
      "source": [
        "**Augmentasi Data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVx_-t-58xFM"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True, #bolak balik image secara vertika, dan true = on\n",
        "    vertical_flip = True,\n",
        "    rotation_range = 90,\n",
        "    height_shift_range = 0.2,\n",
        "    width_shift_range = 0.2,\n",
        "    zoom_range = 0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.7\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeJKP-sb8lWA",
        "outputId": "1936db4f-2ed5-4eb6-e439-fc218fa58240"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = '/content/drive/My Drive/ProjectPrakML/train'\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    color_mode='rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 494 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bab6IIxn9OgV",
        "outputId": "b1768dba-6fe3-4e45-b25f-86dfd76af90d"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "valid_dir = '/content/drive/My Drive/ProjectPrakML/valid'\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size = (150, 150),\n",
        "    color_mode='rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 125 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tLBwEVW-Gq7",
        "outputId": "2092f6fe-3312-460d-8569-434f5652dd7e"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_dir = '/content/drive/My Drive/ProjectPrakML/test'\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (150, 150),\n",
        "    color_mode='rgb',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJBkoGtBLrs"
      },
      "source": [
        "**Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVTxxDt8HSRc"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.Input(shape = (150, 150, 3))\n",
        "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu')(inputs)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "outputs = tf.keras.layers.Dense(3, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = 100,\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=40,\n",
        "            verbose=1, \n",
        "            mode='auto',\n",
        "            cooldown=1\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyIYT9u3M1-V"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.Input(shape = (150, 150, 3))\n",
        "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu')(inputs)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.GlobalMaxPool2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "model2.add(Dense(3, activation='softmax'))\n",
        "outputs = tf.keras.layers.Dense(3, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = 100,\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=40,\n",
        "            verbose=1, \n",
        "            mode='auto',\n",
        "            cooldown=1\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETC0kigOmX4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xN9PEe9mbgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzORt44Vmf2R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_c4I84RmjzR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}